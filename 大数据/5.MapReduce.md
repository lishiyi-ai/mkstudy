## 简介


​	==MapReduce设计的一个理念就是“计算向数据靠拢”，而不是“数据向计算靠拢”，==因为移动数据需要大量的网络传输开销，尤其是在大规模数据环境下，这种开销尤为惊人，所以，移动计算要比移动数据更加经济。

本地计算：在一个集群中，只要有可能，MapReduce框架就会将Map程序就近地在HDFS数据所在的节点运行，即将计算节点和存储节点放在一起运行，从而减少了节点间的数据移动开销。

#### ==Map 和 Reduce 函数==

|  函数  |       输入        |       输出        |                             说明                             |
| :----: | :---------------: | :---------------: | :----------------------------------------------------------: |
|  Map   |    **<k1,v1>**    | **List(<k2,v2>)** | （1）将小数据集进一步解析成一批<key,value>对，输入Map函数中进行处理；（2）每一个输入的<k1,v1>会输出一批<k2,v2>,<k2,v2>是计算的中间结果 |
| Reduce | **<k2,List(v2)>** |    **<k3,v3>**    | 输入的中间结果<k2,List(v2)>中的List(v2)表示是一批属于同一个k2的value |

Map函数的处理过程：**将输入的元素转换成<key,value>形式的键值对**，键和值的类型是任意的，**其中键没有唯一性，不能作为输出的身份标识**。

Reduce函数的处理过程**：将输入的一系列具有相同键的键值对以某种方式组合起来**，输出处理后的键值对，输出结果合并成一个文件。

## MapReduce的工作流程

#### MapReduce的各个执行阶段

​	Map -> Shuffle ->Reduce
​	Shuffle 包括：Partition，Sort，Combine，Merge

#### ==MapReduce 是处理大数据的有力工具，但不是每个任务都可以使用MapReduce 来进行处理。试述适合用MapReduce来处理的任务或者数据集需满足怎样的要求。==

适合用MapReduce来处理的数据集，需要满足一个前提条件: 待**处理的数据集可以分解成许多小的数据集，而且每一个小数据集都可以完全并行地进行处理。**

#### ==MapReduce模型采用Master(JobTracker)-Slave(TaskTracker)结构，试描述JobTracker和TasKTracker的功能。==

MapReduce 框架采用了Master/Slave 架构，包括一个Master 和若干个Slave。Master 上运行JobTracker,Slave 上运行TaskTracker。用户提交的每个计算作业，会被划分成若千个任务。JobTracker 负责作业和任务的调度，监控它们的执行，并重新调度已经失败的任务。TaskTracker负责执行由JobTracker指派的任务。