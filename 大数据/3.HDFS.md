## 分布式文件系统HDFS

​	HDFS默认的一块的大小64MB。

​	分布式文件体系在物理结构上是又计算机集群种的多个节点构成。这些节点分为两类：
​		第一类叫"主节点"(Master Node)，又称为"名称节点"(NameNode);
​		第二类叫"从节点"(Slave Node)，又称为"数据节点"(DataNode);

## HDFS简介

​	HDFS要实现以下目标：
​		兼容廉价的硬件设备，流数据读写，大数据集，简单的文件模型，强大的跨平台兼容性。
​	HDFS的局限性：
​		不适合低延迟数据访问，无法高效存储大量小文件，不支持多用户写入及任意修改文件。

## HDFS的相关概念

#### 块

​	HDFS采用了块的概念，**默认的一个块大小是64MB**，**每个块作为独立的单元进行存储**。

#### ==名称节点 和 数据节点==

##### 名称节点

​	命名节点负责管理分布式文件系统的命名空间，保存了两个核心的数据结构，即 ==FsImage== 和 ==EditLog==。
​	FsImage用于维护文件系统树以及文件树中所有的文件和文件夹的元数据。
​	EditLog记录了所有针对文件的创建、删除、重命名等操作。

##### 数据节点

​	**负责数据的存储和读取**，会根据客户端或者名称节点的调度来进行**数据的存储和检索**，并且向名称节点**定期发送自己所存储的块的列表信息**。

#### 第二名称节点

​	第二名称节点具有两个方面的功能：
​		它可以**完成 EditLog 和 FsImage的合并操作**，减小EditLog文件大小，缩短名称节点重启时间。其次，它可以**作为名称节点的“检查点”**，**保存名称节点中的元数据的信息**。

## HDFS体系结构

#### 命名空间管理

​	**目录、文件 和 块**。整个HDFS集群**只有一个命名空间**，并且**只有唯一一个名称节点**，该节点**负责对这个命名空间进行管理**。

#### 通信协议

​	HDFS通信协议都是构件在**TCP/IP**基础之上。名称节点与数据节点之间则使用数据节点协议进行交互；客户端与数据节点的交互通过**远程过程调用(RPC)**

#### 客户端

​	客户端是用户操作HDFS最常用的方式，HDFS在部署时都提供了客户端。

#### ==HDFS体系结构的局限性(只有一个名称节点)==

（1）**命名空间的限制**。名称节点是保存在内存中的，因此**名称节点能够容纳对象（文件、块）的个数受到内存空间大小的限制**。

（2）**性能的瓶颈**。整个分布式文件系统的吞吐量**受限于单个名称节点的吞吐量**。

（3）**隔离问题**。由于集群只有一个名称节点，只有一个命名空间，**困此无法对不同应用程序进行隔离**。

（4）**集群的可用性**。一旦此**唯一的名称节点发生故障，会导致整个集群变得不可用**。

## HDFS的存储原理

#### 数据的冗余存储

​	采用了多副本方式对数据进行冗余存储：
​		1.加快数据**传输速度**；
​		2.容易检查**数据错误**；
​		3.保证**数据的可靠性**；

#### ==数据的存取策略==

HDFS采用多副本方式对数据进行冗余存储。通常一个数据块的多个副本会被分配到不同的数据节点上，从而带来加快数据传输速度、易检查数据错误和保证数据的可靠性3个方面的优点。具体来说：

1、第一个副本放置在上传文件的数据节点，如果是集群外提交，则**随机挑 选一台磁盘不太满、CPU不太忙的节点**。

2、第二个副本放置在与第一个副本**不同的机架的节点上**。

3、**第三个副本与第一个副本相同机架的其他节点上** 。

4、更多副本的**放置节点随机选取**。

#### ==数据复制==

（1）当客户端要往HDFS中写入一个文件时，此文件首先被写入本地，**并被切分为若干个块**，每个块的大小由HDFS的设定值来决定。

（2）每个块都向HDFS集群中的名称节点发起写请求，名称节点会根据系统中各个数据节点的使用情况，选择一个**数据节点列表**返回给客户端，然后客户端就将**数据首先写入列表中的第一数据节点**，**同时将列表传给第一个数据节点，当第一个数据节点接收到4KB数据时，写入本地，并且向列表中的第二个数据节点发起连接请求，将自己已经接收到的4KB数据和列表传给第二个数据节点，当第二个数据节点接收到4KB数据时，写入本地，并且向列表中的第三个数据节点发起连接请求，依次类推。列表中的多个数据节点形成一条数据复制贩流水线。**

（3）当文件写完时，数据复制也同时完成。

#### ==数据错误与恢复==

（1）**名称节点出错**。Hadoop提供两种机制确保名称节点的安全：**一是将名称节点上的元数据信息同步存储到其他文件系统（如远程挂载的网络文件系统NFS）中**，**二是运行一个第二名称节点，当名称节点宕机后，可将第二名称节点作为一种弥补措施，利用第二名称节点中的元数据信息进行系统恢复。**一般会将上述两种方式结合使用，当名称节点发生宕机时，首先到远程挂载的远程网络文件系统中获取备份的元数据信息，放到第二名称节点上进行恢复，并将第二名称节点作为名称节点来使用。

（2）**数据节点出错**。每个数据节点会**定期向名称节点发送“心跳”信息，向名称节点报告自己的状态**。当数据节点发生故障，或者网络发生断网时，名称节点就无法收到来自一些数据节点的“心跳”信息，这时这些数据节点会被标记为“宕机”，节点上面的所有数据都会被标记为为“不可读”，名称节点不会给再它们发送任何I/O请求。此时，有可能出现一种情形，即一些数据块的副本数量小于冗余因子。名称节点定期检查这种情况，**一旦发现某个数据块的副本数量小于冗余因子，就启动数据冗余复制，为其生成新的副本**。

（3）**数据出错**。客户端读到数据后采用MD5和SHA-1进行数据校验，以确定读取到正确的数据。在文件创建时，客户端会对每一个文件块进行信息摘要，并将此摘要写入同一路径的隐藏文件里面。当客户端对数据校验时发现数据错误，**就会请求到另外一个数据节点读取该文件，并向名称节点报告这个文件块有错误，名称节点会定期检查并重新复制该文件块。**

## HDFS的数据读写过程

#### 读数据的过程

（1）客户端通过**FileSystem.open()**打开文件，相应地，在HDFS文件系统中**DistributedFileSystem具体实了FileSystem**。调用open()方法后，DistributedFileSystem会创建FSDataInputStream，对于HDFS而言，具体的**输入流就是DFSInputStream**。

（2）在DSFInputStream的构造函数中，**输入流通过ClientProtocol.getBlockLocations()远程调用名称节点，获得文件开始部分数据块的保存位置。**对于该数据块，名称节点返回保存该数据的所有节点地址，同时根据距离客户远近对数据节点进行排序**；然后，DistributedFileSystem利用DSFInputStream实例化DFSDataInputStream，返回给客户端**，同时返回数据块的数据节点地址。

（3）获得输入流FSDataInputStream后**，客户端调用read()函数开始读取数据**。输入流根据前面排序结果，选择距离客户最近的数据节点建立连接并读取数据。

（4）数据从该数据节点读书 到客户端。当该数据块读取完毕时，**DFSDataInputStream关闭和数据节点的连接。**

（5）**输入流通过getBlockLocations()方法查找下一个数据块**（如果客户端缓存中已经包含了该数据块的位置信息，就不用调用该方法）。

（6）找到该数据块的最佳数据节点，读取数据。

（7）**当客户端读取完毕数据时，调用FSDataInputStream的close()函数关闭输入流。**

#### 写数据的过程

（1）客户端通过调用FileSystem.create()创建文件，相应地，在HDFS文件系统中**DistributedFileSystem具体实现FileSystem**。调用create()方法后，DistributedFileSystem创建输出流FSDataOutputStream，对于HDFS而言，具体的输出流就是**DFSOutputStream**。

（2）DistributedFileSystem通过RPC远程调用名称节点，在文件系统的命名空间中创建一个新的文件。名称节点执行相关检查，如文件是否已经存在、客户端是否有权限创建文件等。检查通过后，名称节点构造一个新文件，并添加文件信息。远程方法调用结束后**，DistributedFileSystem利用DFSOutputStream实例化FSDataOutputStream**，返回给客户端，客户端使用该输出流写入数据。

（3）获得输出流FSDataOutputStream后，**客户端调用输出流的write()方法向HDFS中对应的文件写入数据**。

（4）客户端向输出流FSDataOutputStream中写入的数据首先被分成一个个的分包，它们被放入DFSOutputStream对象的内部队列。**输出流FSDataOutputStream向名称节点申请保存文件和副本数据块的若干个数据节点**，这些节点形成一个数据管道流。**队列中的分包最后被打包成数据包，发往数据管道的第一个数据节点，第一个数据节点将数据包发送给第二个数据节点，第二个数据节点将数据包发送给第三个数据节点，依次类推，数据包将流经管道上的各个数据节点。**

（5）因各个数据节点位于不同的机器上，数据需要通过网络发送。所以为保证所有数据节点的数据都是准确的，接收到数据的数据节点要向发送者发送“确认包（Ack packet）”。确认包沿着数据管道逆流而上，从数据管道依次经过各个数据节点并最终发往客户端，当客户端收到应答时，它将对应的分包从内部队列移除。不**断执行（3）－（5）步，直到数据全部写完。**

（6）**客户端调用close()方法关闭输出流**，此时后，客户端不再向输出流写入数据，所以，当DFSOutputStream对象内部队列中的分包都收到应答后，即可使用**ClientProtocol.complete()方法通知名称节点关闭文件，完成一次正常的写入文件过程。**

## HDFS编程实践



## ==试述HDFS的冗余数据保存策略==

HDFS采用多副本方式对数据进行冗余存储。通常一个数据块的多个副本会被分配到不同的数据节点上，从而带来加快数据传输速度、易检查数据错误和保证数据的可靠性3个方面的优点。具体来说：

1、第一个副本放置在上传文件的数据节点，如果是集群外提交，则**随机挑 选一台磁盘不太满、CPU不太忙的节点**。

2、第二个副本放置在与第一个副本**不同的机架的节点上**。

3、**第三个副本与第一个副本相同机架的其他节点上** 。

4、更多副本的**放置节点随机选取**。