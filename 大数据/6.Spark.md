

#### ==Spark的四个特点==

​	1.运行速度快，2.容易使用，3.通用性，4.运行模式多样

## ==Scala的优点==

​	1.Scala具备强大的并发性，支持函数式编程，可以更好地支持分布式系统。
​	2.Scala语法简洁，提供 优雅的API
​	3.Scala兼容API，运行速度快，且能融合到Hadoop生态系统中。

## ==Spark和Hadoop对比==

#### Hadoop的缺点

​	1.**表达能力有限**，计算都必须要转化成 Map 和 Reduce 两个操作，但这并不是和所有的情况，难以描述复杂的数据处理过程，
​	2.**磁盘IO开销大**，每次执行都需要从磁盘读取数据，完成计算后**中间结果需要写入磁盘中**。
​	3.**延迟高**，一次计算可能需要分解成一系列按顺序执行的MapReduce任务，由于涉及IO开销，所以产生较高延迟。

#### Spark的优点

​	1.Spark的计算模式也属于MapReduce，但不局限于Map 和 Reduce操作，提供了多种数据集操作类型，**编程模型比MapReduce更灵活**。
​	2.**Spark提供了内存计算**，**中间结果直接放到内存中**，带来了**更高的迭代运算效率**。
​	3.**Spark基于DAG的任务调度执行机制**，要优于MapReduce的迭代执行机制。

## Spark生态系统

Spark所提供的生态系统同时支持**批处理**、**交互式查询**和**流数据处理**。Spark生态系统主要包括SparkCore、SparkSQL、SparkStreaming、MLlib，GraphX等组件。
	Spark Core。包含Spark的基本功能，如**内存计算、任务调度、部署模式、故障恢复、存储管理**等，主要面向**批数据处理**。
	Spark SQL。**允许开发人员直接处理RDD**，同时也可以查询Hive、HBase等外部数据源。**能够统一处理关系表和RDD**。
	Spark Streaming。支持**高吞吐量**、**可容错处理**的**实时流数据处理**，**其核心式将流数据分解成一系列短小的批处理作业，**每个短小的批处理作业都可以使用Spark Core进行快速处理。
	MLlib。**提供常用的机器学习算法的实现**，包括聚类、分类、归类、协同过滤。
	GraphX。Spark用于**图计算的API**，可以认为是Pregel在Spark上的重写及优化。

#### ==大数据处理的主要分类：==

1.**复杂的批量数据处理**：时间跨度通常在数十分钟到数小时。
2.基于**历史数据的交互式查询**：时间跨度通常在数十秒到数分钟。
3.基于**实时数据流的数据处理**：时间跨度通常在数百毫秒到数秒。

#### 从Hadoop + Storm架构转向Spark架构可带来哪些好处？

①　实现**一键式安装和配置、线程级别的任务监控和告警**；

②　**降低硬件集群**、**软件维护**、**任务监控和应用开发的难度**；

③   便于**做成统一的硬件**、**计算平台资源池**。

#### ==Spark对RDD的操作主要分为行动（Action）和转换（Transformation）两种类型，两种类型操作的区别是什么？==

**行动**（Action）：**在数据集上进行运算，返回计算值**。**转换**（Transformation）：基于**现有的数据集创建一个新的数据集**。两者的区别主要在于，**转换接受RDD并返回RDD**，而**行动接受RDD但返回非RDD**（输出一个值或结果）。

#### ==描述SPark的几个主要概念：RDD、DAG、阶段、分区、窄依赖、宽依赖==

RDD：**弹性分布式数据集**的英文缩写，是分布式内存的一个抽象概念，提供了一种**高度受限的共享内存模型**。
DAG：是Directed Acyclic Graph (**有向图无环图**) 的英文缩写，反映RDD之间的依赖关系。
阶段：是**作业的基本调度单位**，一个作业会分为多组任务，每组任务被称为“阶段”，或者也被称为“任务集”。
分区：**一个RDD就是一个分布式对象集合**，本质上是一个只读的分区记录集合，每个RDD可以分成多个分区，每个分区就是一个数据集分段。
窄依赖：**父RDD的一个分区只被一个字RDD的一个分区所使用**就是窄依赖。
宽依赖：**父RDD的一个分区被一个子RDD的多个分区所使用**就是宽依赖。

